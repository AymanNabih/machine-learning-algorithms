{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pprint\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(invalid='raise')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_boston\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labelled(column):\n",
    "    mean = column.mean()\n",
    "    for i in range(column.shape[0]):\n",
    "        column[i] = int(column[i] >= mean) \n",
    "    return column\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "iris = load_iris()\n",
    "dataset = iris\n",
    "\n",
    "X = iris.data\n",
    "y = dataset.target\n",
    "\n",
    "#converting iris dataset's continuous features, to discrete features\n",
    "for i in range(X.shape[1]):\n",
    "    X[:,i] = make_labelled(X[:,i])\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, df, feature=None, value=None, score=None, children=None):\n",
    "        #datapoints for current node\n",
    "        self.df = df\n",
    "        \n",
    "        #feature name\n",
    "        self.feature = feature\n",
    "        \n",
    "        #feature value\n",
    "        self.value = value\n",
    "        \n",
    "        #node impurity\n",
    "        self.score = score\n",
    "        \n",
    "        #child nodes (a node for each value of feature)\n",
    "        #mapping of {value:child node}\n",
    "        self.children = children\n",
    "        \n",
    "        #if node is a leaf node then setting the class label for this leaf node\n",
    "        if self.children is None:\n",
    "            try:\n",
    "                self.label\n",
    "            except:\n",
    "                self.label = self.df.y.unique()[0]\n",
    "                \n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.children is not None:\n",
    "            return \"\"\"\n",
    "                feature: {0}\n",
    "                score: {1}\n",
    "                children: {2}\n",
    "            \"\"\".replace('    ','').strip('\\n').format(self.feature, self.score, len(self.children))\n",
    "        else:\n",
    "            return \"\"\"\n",
    "                value: {0}\n",
    "                score: {1}\n",
    "                label: {2}\n",
    "            \"\"\".replace('    ','').strip('\\n').format(self.value, self.score, self.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth=None, split='gini_index', feature_names=None, verbose=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.split = split\n",
    "        self.feature_names = feature_names\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self._check_params(X, y)\n",
    "        \n",
    "        #unique classes and no of features\n",
    "        self.classes = list(set(y))\n",
    "        self.xdim = X.shape[1]\n",
    "        \n",
    "        #creating dataframe\n",
    "        df = pd.DataFrame(X)\n",
    "        if self.feature_names != None:\n",
    "            df.columns = self.feature_names\n",
    "        df['y'] = y\n",
    "        self.df = df\n",
    "        \n",
    "        #constructing decision tree\n",
    "        self._build_decision_tree(self.df)\n",
    "        \n",
    "        self.fitted_ = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.fitted_ == None:\n",
    "            raise Exception('\"predict()\" called before fit()')\n",
    "        else:\n",
    "            y_preds = []\n",
    "            for x in X:\n",
    "                temp = self.root\n",
    "                \n",
    "                #traversing our tree until we have reached the leaf node\n",
    "                while True:\n",
    "                    if temp.children is None: break\n",
    "                    else:\n",
    "                        index = self.feature_names.index(temp.feature)\n",
    "                        temp = temp.children[x[index]]\n",
    "                    \n",
    "                #we are at leaf node therefore setting class label of leaf node as our prediction\n",
    "                y_pred = temp.label\n",
    "                y_preds.append(y_pred)\n",
    "            return np.array(y_preds)\n",
    "    \n",
    "    \n",
    "    def _build_decision_tree(self, df):\n",
    "        #initializing empty queue\n",
    "        queue = deque()\n",
    "        root = None\n",
    "        \n",
    "        while True:\n",
    "            if len(queue) == 0:\n",
    "                #getting purity score for each feature\n",
    "                #returns {feature=>score}\n",
    "                scores = self._scores(df)\n",
    "\n",
    "                #getting feature to split on (feature with minimum impurity)\n",
    "                feature = min(scores, key=lambda k: scores[k])\n",
    "                \n",
    "                #getting score of selected feature\n",
    "                score = scores[feature]\n",
    "\n",
    "                #if node is pure\n",
    "                if score == 0:\n",
    "                    #creating root node\n",
    "                    root = Node(df=df, score=scores[feature])\n",
    "                    root.label = df.y[0]\n",
    "                    \n",
    "                #if all features have same impurity\n",
    "                #which means dataset cannot divided further\n",
    "                #therefore selecting class label with highest frequency as leaf node's label\n",
    "                elif len(np.unique(list(scores.values()))) == 1:\n",
    "                    #creating root node\n",
    "                    root = Node(df=df, score=scores[feature])\n",
    "                    node.label = np.argmax(np.bincount(df.y))\n",
    "                    \n",
    "                #else continuing creating building tree by child nodes\n",
    "                else:\n",
    "                    #creating root node\n",
    "                    root = Node(df=df, feature=feature, score=scores[feature])\n",
    "                    \n",
    "                    #getting unique values for feature to split on\n",
    "                    values = df[feature].unique()\n",
    "                    \n",
    "                    #setting children of current node\n",
    "                    #for each value of feature creating a child with its specific df and value\n",
    "                    children = {}\n",
    "                    for value in values:\n",
    "                        child = Node(df=df[df[feature] == value], value=value)\n",
    "                        children[value] = child\n",
    "\n",
    "                    #adding children to queue \n",
    "                    queue = queue + deque(children.values())\n",
    "\n",
    "                    #setting child nodes\n",
    "                    root.children = children\n",
    "                \n",
    "                #adding root as instance variable for tree traversal in prediction phase\n",
    "                self.root = root\n",
    "                \n",
    "                #printing node info if verbose is True\n",
    "                if self.verbose:\n",
    "                    print(root)\n",
    "                    print()\n",
    "            elif len(queue) > 0:\n",
    "                node = queue.popleft()\n",
    "                \n",
    "                #getting impurity score for each feature\n",
    "                #returns {feature=>score}\n",
    "                scores = self._scores(node.df)\n",
    "\n",
    "                #setting impurity score of node (lowest value)\n",
    "                node.score = scores[feature]\n",
    "                \n",
    "                #if node is pure\n",
    "                if node.score == 0:\n",
    "                    pass\n",
    "                \n",
    "                #if all features have same impurity\n",
    "                #which means dataset cannot be divided further\n",
    "                #therefore selecting class label with highest frequency as leaf node's label\n",
    "                elif len(np.unique(list(scores.values()))) == 1:\n",
    "                    node.label = np.argmax(np.bincount(node.df.y))\n",
    "                    \n",
    "                #else continuing creating building tree by child nodes\n",
    "                else:\n",
    "                    #getting feature to split on (feature with minimum impurity)\n",
    "                    feature = min(scores, key=lambda k: scores[k])\n",
    "\n",
    "                    #setting feature to split on\n",
    "                    node.feature = feature\n",
    "\n",
    "                    #getting unique values for feature to split on\n",
    "                    values = node.df[feature].unique()\n",
    "                \n",
    "                    #setting children of current node\n",
    "                    #for each value of feature creating a child with its specific df and value\n",
    "                    children = {}\n",
    "                    for value in values:\n",
    "                        child = Node(df=node.df[node.df[feature] == value], value=value)\n",
    "                        children[value] = child\n",
    "\n",
    "                    #adding children to queue \n",
    "                    queue = queue + deque(children.values())\n",
    "\n",
    "                    #setting child nodes\n",
    "                    node.children = children\n",
    "                    \n",
    "                #printing node info if verbose is True\n",
    "                if self.verbose:\n",
    "                    print(node)\n",
    "                    print()\n",
    "            \n",
    "            if len(queue) == 0:\n",
    "                break\n",
    "    \n",
    "    def _cost(self, groups):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _gini_index(self, df, feature):\n",
    "        gini_index = 0\n",
    "\n",
    "        #getting unique values of current feature\n",
    "        values = df[feature].unique()\n",
    "\n",
    "        gindices = [1 for _ in range(len(values))]\n",
    "\n",
    "        #for each value of feature calculating gini value\n",
    "        for i,value in enumerate(values):\n",
    "            for c in self.classes:\n",
    "                gindices[i] -= (df.loc[df[feature] == value].loc[df.y == c].count().y / df[df[feature] == value].count().y) ** 2\n",
    "\n",
    "        #calculating gini index\n",
    "        for i, value in enumerate(values):\n",
    "            gini_index += gindices[i] * (df[df[feature] == value].count().y / df.count().y)\n",
    "\n",
    "        return gini_index\n",
    "    \n",
    "    \n",
    "    def _gini_indices(self, df):\n",
    "        gini_indices = {}\n",
    "        \n",
    "        #getting gini index for each feature\n",
    "        for feature in df.columns[0:-1]:\n",
    "            gini_indices[feature] = self._gini_index(df, feature)\n",
    "            \n",
    "        return gini_indices\n",
    "        \n",
    "    \n",
    "    #@TODO\n",
    "    def _proportions(self, df):\n",
    "        total_rows = len(df)\n",
    "        ps = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            ps[c] = len(df[df.y == c]).count().y / total_rows\n",
    "        \n",
    "        return ps\n",
    "    \n",
    "    \n",
    "    def _entropy(self, ps):\n",
    "        return -(ps * np.log2(ps)).sum()\n",
    "                               \n",
    "        \n",
    "    #@TODO\n",
    "    def _gain(self, original, children):\n",
    "        original_ps = self._proportions(original)\n",
    "        original_entropy = self._entropy(original_ps)\n",
    "        \n",
    "        split_entropy = 0\n",
    "        for child in children:\n",
    "            child_ps = self._proportions(children.df)\n",
    "            split_entropy += self._entropy(child_ps)\n",
    "        split_entropy = split_entropy / len(children)\n",
    "        \n",
    "        return original_entropy - split_entropy\n",
    "    \n",
    "    \n",
    "    #@TODO\n",
    "    def _split_entropy(self, original, children):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    #@TODO\n",
    "    def _gain_ratio(self, df):\n",
    "        scores = {}\n",
    "        \n",
    "        for feature in df.columns:\n",
    "            groups = df.groupby(by=feature)\n",
    "            feature_df = groups.get_group(feature)\n",
    "            feature_dfs.append(feature_df)\n",
    "            \n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    def _scores(self, df):\n",
    "        if self.split == 'gain_ratio':\n",
    "            scores = self_gain_ratios(df)\n",
    "        elif self.split == 'gini_index':\n",
    "            scores = self._gini_indices(df)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    #@TODO\n",
    "    def print_decision_tree(self):\n",
    "        pass\n",
    "    \n",
    "                               \n",
    "    def _check_params(self, X, y=None):\n",
    "        if type(self.split) != str:\n",
    "            raise Exception('type of \"split\" should be string')\n",
    "        elif self.split not in ('gini_index', 'gain_ratio'):\n",
    "            warnings.warn('invalid value of \"split\", using default(\"gini_index\") value')\n",
    "            self.split = 'gini_index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier vs CustomDecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815789473684\n",
      "0.815789473684\n"
     ]
    }
   ],
   "source": [
    "skModel = DecisionTreeClassifier().fit(xTrain, yTrain)\n",
    "custModel = CustomDecisionTreeClassifier(feature_names=dataset.feature_names).fit(xTrain, yTrain)\n",
    "\n",
    "print(skModel.score(xTest, yTest))\n",
    "print(custModel.score(xTest, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71428571  0.91666667  0.83333333]\n",
      "[ 0.71428571  0.91666667  0.83333333]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(estimator=skModel, X=xTest, y=yTest))\n",
    "print(cross_val_score(estimator=custModel, X=xTest, y=yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting & Understanding DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
